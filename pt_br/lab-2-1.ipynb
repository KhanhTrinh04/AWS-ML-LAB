{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version: 02.14.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratório 2.1: Aplicação do ML a um problema de PLN\n",
    "\n",
    "Neste laboratório, você usará o modelo de machine learning (ML) integrado ao Amazon SageMaker, __LinearLearner__, para prever o campo __isPositive__ do conjunto de dados da avaliação.\n",
    "\n",
    "## Apresentação do cenário de negócios\n",
    "Você trabalha para uma loja de varejo on-line que quer melhorar o engajamento dos clientes que publicaram avaliações negativas. A empresa quer detectar avaliações negativas e atribuir a elas a um agente de atendimento ao cliente para tratar do assunto.\n",
    "\n",
    "Sua tarefa é usar o ML para detectar avaliações negativas e resolver parte desse problema. Você recebeu acesso a um conjunto de dados que contém avaliações, que foram classificadas como positivas ou negativas. Use esse conjunto de dados para treinar um modelo de ML e prever o sentimento das próximas avaliações.\n",
    "\n",
    "## Sobre esse conjunto de dados\n",
    "O arquivo [AMAZON-REVIEW-DATA-CLASSIFICATION.csv](https://github.com/aws-samples/aws-machine-learning-university-accelerated-nlp/tree/master/data/examples) contém avaliações reais de produtos, e elas contêm dados de texto e dados numéricos. Cada avaliação é classificada como _positive (1)_ ou _negative (0)_.\n",
    "\n",
    "O conjunto de dados contém os seguintes recursos:\n",
    "* __reviewText:__ texto da avaliação\n",
    "* __summary:__ resumo da avaliação\n",
    "* __verified:__ se a compra foi verificada (Verdadeiro ou Falso)\n",
    "* __time:__ descrição de data/hora UNIX da avaliação\n",
    "* __log_votes:__ registro de votos ajustado por logaritmo (1+votos)\n",
    "* __isPositive:__ se a avaliação é positiva ou negativa (1 ou 0)\n",
    "\n",
    "O conjunto de dados deste laboratório está sendo fornecido a você com permissão da Amazon e está sujeito aos termos de Licença e acesso da Amazon (disponíveis em https://www.amazon.com/gp/help/customer/display.html?nodeId=201909000). É expressamente proibido copiar, modificar, vender, exportar ou usar este conjunto de dados com outro propósito que não seja para fins de conclusão deste laboratório.\n",
    "\n",
    "## Etapas do laboratório\n",
    "\n",
    "Para concluir o laboratório, siga estas etapas:\n",
    "\n",
    "1. [Leitura do conjunto de dados](#1.-Reading-the-dataset)\n",
    "2. [Realização da análise exploratória de dados](#2.-Performing-exploratory-data-analysis)\n",
    "3. [Processamento de texto: remoção de palavras irrelevantes e stemming](#3.-Text-processing:-Removing-stopwords-and-stemming)\n",
    "4. [Divisão dos dados para treinamento, validação e teste](#4.-Splitting-training,-validation,-and-test-data)\n",
    "5. [Processamento de dados com pipelines e um ColumnTransformer](#5.-Processing-data-with-pipelines-and-a-ColumnTransformer)\n",
    "6. [Treinamento de um classificador com um algoritmo integrado ao SageMaker](#6.-Training-a-classifier-with-a-built-in-SageMaker-algorithm)\n",
    "7. [Avaliação do modelo](#7.-Evaluating-the-model)\n",
    "8. [Implementação do modelo em um endpoint](#8.-Deploying-the-model-to-an-endpoint)\n",
    "9. [Teste do endpoint](#9.-Testing-the-endpoint)\n",
    "10. [Remoção de artefatos do modelo](#10.-Cleaning-up-model-artifacts)\n",
    "    \n",
    "## Envio do trabalho\n",
    "\n",
    "1. No console do laboratório, escolha **Submit** (Enviar) para registrar seu progresso e, quando solicitado, escolha **Yes** (Sim).\n",
    "\n",
    "1. Se os resultados não forem exibidos após alguns minutos, volte ao topo destas instruções e escolha **Grades** (Notas).\n",
    "\n",
    "     **Dica**: você pode enviar seu trabalho várias vezes. Depois de alterar o trabalho, escolha **Submit** (Enviar) novamente. Seu último envio é o que será gravado para o laboratório.\n",
    "\n",
    "1. Para ver o feedback detalhado sobre seu trabalho, escolha **Details** (Detalhes) e depois **View Submission Report** (Ver relatório do envio).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, instale/atualize o pip, o sagemaker e a scikit-learn.\n",
    "\n",
    "[scikit-learn] (https://scikit-learn.org/stable/) é uma biblioteca de machine learning de código aberto. Ela oferece várias ferramentas para ajustar modelos, pré-processar dados, selecionar e avaliar modelos e muitos outros utilitários."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upgrade dependencies\n",
    "!pip install --upgrade pip\n",
    "!pip install --upgrade scikit-learn\n",
    "!pip install --upgrade sagemaker\n",
    "!pip install --upgrade botocore\n",
    "!pip install --upgrade awscli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Leitura do conjunto de dados\n",
    "([Ir para o topo](#Lab-2.1:-Applying-ML-to-an-NLP-Problem))\n",
    "\n",
    "Use a biblioteca __pandas__ para ler o conjunto de dados. [Pandas] (https://pandas.pydata.org/pandas-docs/stable/index.html) é uma biblioteca Python popular usada para analisar dados. Ela oferece recursos de manipulação de dados, limpeza e controle de dados, além de visualizações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/AMAZON-REVIEW-DATA-CLASSIFICATION.csv')\n",
    "\n",
    "print('The shape of the dataset is:', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe as primeiras cinco linhas do conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível alterar as opções na atividade para exibir mais dados de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode analisar entradas específicas se necessário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[[580]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É importante saber com quais tipos de dados você está lidando. Você pode usar  `dtypes` no dataframe para exibir os tipos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Realização da análise exploratória de dados\n",
    "([Ir para o topo](#Lab-2.1:-Applying-ML-to-an-NLP-Problem))\n",
    "\n",
    "Agora você verá a distribuição de destinos do conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['isPositive'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O problema de negócios é identificar as avaliações negativas (_0_). Porém, o ajuste do modelo para o linear learner encontra valores positivos (_1_) por padrão. Você pode trocar os valores negativos (_0_) e os valores positivos (_1_) para fazer esse processo funcionar melhor. Assim, será possível ajustar o modelo com mais facilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace({0:1, 1:0})\n",
    "df['isPositive'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confira o número de valores ausentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os campos de texto têm valores ausentes. Geralmente, você decide o que fazer com esses valores. É possível remover os dados ou preenchê-los com um texto-padrão. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Processamento de texto: remoção de palavras irrelevantes e stemming\n",
    "([Ir para o topo](#Lab-2.1:-Applying-ML-to-an-NLP-Problem))\n",
    "\n",
    "Nesta tarefa, você removerá algumas das palavras irrelevantes e fará o stemming nos dados de texto. Você normalizará os dados para reduzir a quantidade de informações diferentes com as quais é preciso lidar.\n",
    "\n",
    "[nltk](https://www.nltk.org/) é uma plataforma popular para trabalhar com dados de linguagem humana. Ela oferece interfaces e funções para processar texto para classificação, tokenização, stemming, marcação, análise e raciocínio semântico. \n",
    "\n",
    "Depois de importá-la, você só pode baixar a funcionalidade necessária. Neste exemplo, você usará:\n",
    "\n",
    "- **punkt** é um tokenizador de frases.\n",
    "- **stopwords** apresenta uma lista de palavras irrelevantes que você pode usar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the library and functions\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na seção a seguir, você criará os processos para remover as palavras irrelevantes e limpar o texto. A biblioteca Natural Language Toolkit (NLTK) oferece uma lista de palavras irrelevantes comuns. Você usará a lista, mas primeiro removerá algumas palavras dela. As palavras irrelevantes mantidas no texto são úteis para identificar o sentimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Get a list of stopwords from the NLTK library\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "# These words are important for your problem. You don't want to remove them.\n",
    "excluding = ['against', 'not', 'don', 'don\\'t','ain', 'are', 'aren\\'t', 'could', 'couldn\\'t',\n",
    "             'did', 'didn\\'t', 'does', 'doesn\\'t', 'had', 'hadn\\'t', 'has', 'hasn\\'t', \n",
    "             'have', 'haven\\'t', 'is', 'isn\\'t', 'might', 'mightn\\'t', 'must', 'mustn\\'t',\n",
    "             'need', 'needn\\'t','should', 'shouldn\\'t', 'was', 'wasn\\'t', 'were', \n",
    "             'weren\\'t', 'won\\'t', 'would', 'wouldn\\'t']\n",
    "\n",
    "# New stopword list\n",
    "stopwords = [word for word in stop if word not in excluding]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O stemizador snowball stemiza as palavras. Por exemplo, o verbo “caminhando” será transformado em “caminh”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É preciso realizar outras tarefas de normalização nos dados. A seguinte função:\n",
    "\n",
    "- Substitui todos os valores ausentes por uma string vazia\n",
    "- Converte o texto em letras minúsculas\n",
    "- Remove espaços em branco à esquerda ou à direita\n",
    "- Remove espaços e recuos extras\n",
    "- Remove marcações HTML\n",
    "\n",
    "No loop  `for`, todas as palavras que __NOT__ são numéricas, têm mais de dois caracteres e não estão na lista de palavras irrelevantes são mantidas e retornadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(texts): \n",
    "    final_text_list=[]\n",
    "    for sent in texts:\n",
    "        \n",
    "        # Check if the sentence is a missing value\n",
    "        if isinstance(sent, str) == False:\n",
    "            sent = ''\n",
    "            \n",
    "        filtered_sentence=[]\n",
    "        \n",
    "        sent = sent.lower() # Lowercase \n",
    "        sent = sent.strip() # Remove leading/trailing whitespace\n",
    "        sent = re.sub('\\s+', ' ', sent) # Remove extra space and tabs\n",
    "        sent = re.compile('<.*?>').sub('', sent) # Remove HTML tags/markups:\n",
    "        \n",
    "        for w in word_tokenize(sent):\n",
    "            # Applying some custom filtering here, feel free to try different things\n",
    "            # Check if it is not numeric and its length>2 and not in stopwords\n",
    "            if(not w.isnumeric()) and (len(w)>2) and (w not in stopwords):  \n",
    "                # Stem and add to filtered list\n",
    "                filtered_sentence.append(snow.stem(w))\n",
    "        final_string = \" \".join(filtered_sentence) # Final string of cleaned words\n",
    " \n",
    "        final_text_list.append(final_string)\n",
    "        \n",
    "    return final_text_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Divisão dos dados para treinamento, validação e teste\n",
    "([Ir para o topo](#Lab-2.1:-Applying-ML-to-an-NLP-Problem))\n",
    "\n",
    "Nesta etapa, você usará a função sklearn [__train_test_split()__](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) a fim de dividir o conjunto de dados para treinamento (80%), validação (10%) e teste (10%).\n",
    "\n",
    "Os dados de treinamento serão usados para treinar o modelo, que depois será testado com os dados de teste. O conjunto de validação é usado depois que o modelo foi treinado para apresentar métricas sobre a performance do modelo em dados reais. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(df[['reviewText', 'summary', 'time', 'log_votes']],\n",
    "                                                  df['isPositive'],\n",
    "                                                  test_size=0.20,\n",
    "                                                  shuffle=True,\n",
    "                                                  random_state=324\n",
    "                                                 )\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val,\n",
    "                                                y_val,\n",
    "                                                test_size=0.5,\n",
    "                                                shuffle=True,\n",
    "                                                random_state=324)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, com o conjunto de dados dividido, você pode executar a função  `process_text` definida acima em cada um dos recursos de texto nos conjuntos de treinamento, teste e validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Processing the reviewText fields')\n",
    "X_train['reviewText'] = process_text(X_train['reviewText'].tolist())\n",
    "X_val['reviewText'] = process_text(X_val['reviewText'].tolist())\n",
    "X_test['reviewText'] = process_text(X_test['reviewText'].tolist())\n",
    "\n",
    "print('Processing the summary fields')\n",
    "X_train['summary'] = process_text(X_train['summary'].tolist())\n",
    "X_val['summary'] = process_text(X_val['summary'].tolist())\n",
    "X_test['summary'] = process_text(X_test['summary'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Processamento de dados com pipelines e um ColumnTransformer\n",
    "([Ir para o topo](#Lab-2.1:-Applying-ML-to-an-NLP-Problem))\n",
    "\n",
    "Geralmente, você precisa realizar muitas tarefas nos dados antes de usá-los para treinar um modelo. Essas etapas também devem ser feitas em todos os dados usados para inferência após a implementação do modelo. Uma boa forma de organizar as etapas é definir um _pipeline_. Um pipeline é uma coleção de tarefas de processamento que serão realizadas nos dados. É possível criar pipelines diferentes para processar campos diferentes. Como você está trabalhando com dados numéricos e de texto, defina os seguintes pipelines:\n",
    "\n",
    "   * Para o pipeline de recursos numéricos, o __numerical_processor__ usa um MinMaxScaler. (Não é necessário dimensionar os recursos ao usar árvores de decisão, mas é importante fazer isso para saber como usar mais transformações de dados.) Caso você queira realizar diferentes tipos de processamento em diferentes recursos numéricos, crie pipelines diferentes, como os que são mostrados para os dois recursos de texto.\n",
    "   * Para o pipeline de recursos de texto, o __text_processor__ usa  `CountVectorizer()` nos campos de texto.\n",
    "   \n",
    "As preparações seletivas dos recursos do conjunto de dados são reunidas em um ColumnTransformer coletivo, que será usado em um pipeline com um estimador. Esse processo garante que as transformações sejam realizadas automaticamente nos dados brutos quando você ajusta o modelo ou faz previsões. (Por exemplo, ao avaliar o modelo em um conjunto de dados de validação por meio da validação cruzada ou ao fazer previsões em um conjunto de dados de teste no futuro.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab model features/inputs and target/output\n",
    "numerical_features = ['time',\n",
    "                      'log_votes']\n",
    "\n",
    "text_features = ['summary',\n",
    "                 'reviewText']\n",
    "\n",
    "model_features = numerical_features + text_features\n",
    "model_target = 'isPositive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "### COLUMN_TRANSFORMER ###\n",
    "##########################\n",
    "\n",
    "# Preprocess the numerical features\n",
    "numerical_processor = Pipeline([\n",
    "    ('num_imputer', SimpleImputer(strategy='mean')),\n",
    "    ('num_scaler', MinMaxScaler()) \n",
    "                                ])\n",
    "# Preprocess 1st text feature\n",
    "text_processor_0 = Pipeline([\n",
    "    ('text_vect_0', CountVectorizer(binary=True, max_features=50))\n",
    "                                ])\n",
    "\n",
    "# Preprocess 2nd text feature (larger vocabulary)\n",
    "text_precessor_1 = Pipeline([\n",
    "    ('text_vect_1', CountVectorizer(binary=True, max_features=150))\n",
    "                                ])\n",
    "\n",
    "# Combine all data preprocessors from above (add more, if you choose to define more!)\n",
    "# For each processor/step specify: a name, the actual process, and finally the features to be processed\n",
    "data_preprocessor = ColumnTransformer([\n",
    "    ('numerical_pre', numerical_processor, numerical_features),\n",
    "    ('text_pre_0', text_processor_0, text_features[0]),\n",
    "    ('text_pre_1', text_precessor_1, text_features[1])\n",
    "                                    ]) \n",
    "\n",
    "### DATA PREPROCESSING ###\n",
    "##########################\n",
    "\n",
    "print('Datasets shapes before processing: ', X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "X_train = data_preprocessor.fit_transform(X_train).toarray()\n",
    "X_val = data_preprocessor.transform(X_val).toarray()\n",
    "X_test = data_preprocessor.transform(X_test).toarray()\n",
    "\n",
    "print('Datasets shapes after processing: ', X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que o número de recursos nos conjuntos de dados passou de 4 para 202."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Treinamento de um classificador com um algoritmo integrado ao SageMaker\n",
    "([Ir para o topo](#Lab-2.1:-Applying-ML-to-an-NLP-Problem))\n",
    "\n",
    "Nesta etapa, você chamará o algoritmo  `LinearLearner()` do SageMaker com as seguintes opções:\n",
    "* __Permissions -__  `role` está configurado como a role do AWS Identity and Access Management (IAM) do ambiente atual.\n",
    "* __Compute power -__ Você usará os parâmetros  `train_instance_count` e  `train_instance_type`. Este exemplo usa um recurso  `ml.m4.xlarge` para o treinamento. É possível alterar o tipo de instância dependendo de suas necessidades. (Por exemplo, você pode usar GPUs para redes neurais.) \n",
    "* __Model type -__  `predictor_type` está configurado como __`binary_classifier`__, porque você está lidando com um problema de classificação binária. É possível usar __`multiclass_classifier`__ se há três ou mais classes envolvidas ou usar __`regressor`__ para um problema de regressão.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "# Call the LinearLearner estimator object\n",
    "linear_classifier = sagemaker.LinearLearner(role=sagemaker.get_execution_role(),\n",
    "                                           instance_count=1,\n",
    "                                           instance_type='ml.m4.xlarge',\n",
    "                                           predictor_type='binary_classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para definir as partes de treinamento, validação e teste do estimador, use a função  `record_set()` do  `binary_estimator`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_records = linear_classifier.record_set(X_train.astype('float32'),\n",
    "                                            y_train.values.astype('float32'),\n",
    "                                            channel='train')\n",
    "val_records = linear_classifier.record_set(X_val.astype('float32'),\n",
    "                                          y_val.values.astype('float32'),\n",
    "                                          channel='validation')\n",
    "test_records = linear_classifier.record_set(X_test.astype('float32'),\n",
    "                                           y_test.values.astype('float32'),\n",
    "                                           channel='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função  `fit()` aplica uma versão distribuída do algoritmo Stochastic Gradient Descent (SGD), e você envia os dados para ele. Os registros foram desabilitados com  `logs=False`. É possível remover esse parâmetro para ver mais detalhes sobre o processo. __Esse processo leva cerca de 3 a 4 minutos em uma instância ml.m4.xlarge.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_classifier.fit([train_records,\n",
    "                       val_records,\n",
    "                       test_records],\n",
    "                       logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Avaliação do modelo\n",
    "([Ir para o topo](#Lab-2.1:-Applying-ML-to-an-NLP-Problem))\n",
    "\n",
    "Use a análise do SageMaker para ver métricas de performance (de sua escolha) do conjunto de testes. Esse processo não exige a implementação do modelo. \n",
    "\n",
    "O linear learner apresenta métricas que são calculadas durante o treinamento. É possível usar essas métricas ao ajustar o modelo. As métricas disponíveis para o conjunto de validação são:\n",
    "\n",
    "- objective_loss - No caso de um problema de classificação binária, será o valor médio da perda logística para cada época\n",
    "- binary_classification_accuracy - A precisão do modelo final no conjunto de dados, ou seja, quantas previsões o modelo acertou\n",
    "- precision - Quantifica o número de previsões de classes positivas que são de fato positivas\n",
    "- recall - Quantifica o número de previsões de classes positivas\n",
    "- binary_f_beta - A média harmônica das métricas de precisão e recall\n",
    "\n",
    "Neste exemplo, é importante observar quantas previsões estavam corretas. O uso da métrica **binary_classification_accuracy** é apropriado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.analytics.TrainingJobAnalytics(linear_classifier._current_job_name, \n",
    "                                         metric_names = ['test:binary_classification_accuracy']\n",
    "                                        ).dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O valor aproximado de 0,85 deve aparecer. O número pode ser diferente, mas deve estar em torno desse valor. Isso quer dizer que o modelo prevê, com precisão, a resposta correta em 85% do tempo. Dependendo do caso de negócios, talvez seja necessário ajustar os hiperparâmetros para melhorar o modelo ainda mais ou fazer engenharia de recursos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Implementação do modelo em um endpoint\n",
    "([Ir para o topo](#Lab-2.1:-Applying-ML-to-an-NLP-Problem))\n",
    "\n",
    "Nesta última parte do exercício, você implementará o modelo em outra instância de sua escolha. É possível usar esse modelo em um ambiente de produção. Os endpoints implementados podem ser usados com outros serviços da AWS, como o AWS Lambda e o Amazon API Gateway. Para saber mais, veja a seguinte demonstração: [Chamar um endpoint de modelo do Amazon SageMaker usando o Amazon API Gateway e o AWS Lambda] (https://aws.amazon.com/blogs/machine-learning/call-an-amazon-sagemaker-model-endpoint-using-amazon-api-gateway-and-aws-lambda/).\n",
    "\n",
    "Para implementar o modelo, execute a seguinte célula: É possível usar diferentes tipos de instância, como: _ml.t2.medium_, _ml.c4.xlarge_), entre outras. __Esse processo levará de 7 a 8 minutos.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linear_classifier_predictor = linear_classifier.deploy(initial_instance_count = 1,\n",
    "                                                       instance_type = 'ml.c5.large'\n",
    "                                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Teste do endpoint\n",
    "([Ir para o topo](#Lab-2.1:-Applying-ML-to-an-NLP-Problem))\n",
    "\n",
    "Agora que o endpoint está implementado, você enviará os dados de teste para ele e verá previsões dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get test data in batch size of 25 and make predictions.\n",
    "prediction_batches = [linear_classifier_predictor.predict(batch)\n",
    "                      for batch in np.array_split(X_test.astype('float32'), 25)\n",
    "                     ]\n",
    "\n",
    "# Get a list of predictions\n",
    "print([pred.label['score'].float32_tensor.values[0] for pred in prediction_batches[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Remoção de artefatos do modelo\n",
    "([Ir para o topo](#Lab-2.1:-Applying-ML-to-an-NLP-Problem))\n",
    "\n",
    "Siga as etapas abaixo para excluir o endpoint depois que terminar de usá-lo. \n",
    "\n",
    "**Dica:** lembre-se de que, se você usar sua própria conta, serão registradas cobranças caso você não exclua o endpoint e outros recursos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_classifier_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parabéns!\n",
    "\n",
    "Neste laboratório, você acompanhou um problema de PLN muito simples. Com um conjunto de dados classificado, você usou um tokenizador e um codificador simples para gerar os dados necessários para treinar um modelo de linear learner. Depois, você implementou o modelo e fez algumas previsões. Se você estivesse realizando esse processo de verdade, provavelmente precisaria obter os dados e identificá-los para o treinamento. Uma opção é usar um algoritmo pré-treinado ou um serviço gerenciado. Também provavelmente seria necessário ajustar os hiperparâmetros para melhorar o modelo ainda mais.\n",
    "\n",
    "Você concluiu o laboratório e agora pode encerrá-lo seguindo as instruções do guia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "©2023 Amazon Web Services, Inc. ou suas afiliadas. Todos os direitos reservados. Este trabalho não pode ser reproduzido ou redistribuído, no todo ou em parte, sem a permissão prévia por escrito da Amazon Web Services, Inc. É proibido copiar, emprestar ou vender para fins comerciais. Todas as marcas comerciais pertencem a seus proprietários."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3.8.5 32-bit",
   "name": "python385jvsc74a57bd012bdb53ebf8de4a8c3e84b62f6391946884c7c7585d9344b706f290a85145ccc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "12bdb53ebf8de4a8c3e84b62f6391946884c7c7585d9344b706f290a85145ccc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
